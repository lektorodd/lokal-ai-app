# lokal-ai-app

Tester litt python, KI og Ollama. 
Lokale modellar som kan lastast ned og k칮yrast p친 maskina di. Ingen data som vert delt med andre...

## llama-app-v2.py 
er med langchain, for 친 enklare kunne legge til fleire modellar. Inkluderer str칮yming av svar.

<img src="d칮mev2.png" width="75%" />

## llama-app.py
er utan langchain, og har ikkje str칮yming av svar. F칮rste versjon.

<img src="d칮me.png" width="75%" />


## Du treng
- **[ollama](ollama.ai)** for 친 lasta ned/k칮yra spr친kmodellen
    - Ein spr친kmodell (feks **[llama 3.1 8b](https://ollama.com/library/llama3.1)**) 
- **[Streamlit](https://streamlit.io/)** for 친 kj칮ra appen
- **[游댕 Langchain](https://python.langchain.com/v0.2/docs/introduction/)** for 친 enklare kunna bytta fr친 Ollama til feks. OpenAI etc. 

### Python - requirements

For 친 installera biblioteka i python (gjerne i eit conda env) kan du k칮yra

```bash
pip install -r requirements.txt
```